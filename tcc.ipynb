{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BrunaCFerreiraAzevedo/PredicaoFraude/blob/V1/tcc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **UTILIZANDO RANDOM FOREST // Criando Modelo Base**"
      ],
      "metadata": {
        "id": "zdnvnE7jACAu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importando bibliotecas de treino\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.ensemble import IsolationForest\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd\n",
        "!pip install opendatasets --upgrade --quiet\n",
        "\n",
        "import opendatasets as od\n",
        "download_url = 'https://www.kaggle.com/datasets/jainilcoder/online-payment-fraud-detection'\n",
        "od.download(download_url)\n",
        "\n",
        "\n",
        "df= pd.read_csv('./online-payment-fraud-detection/onlinefraud.csv')\n",
        "df\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "1aaN3oQs_LjJ",
        "outputId": "7f8dff7a-f98d-4800-b93d-f78cabc810fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username:"
          ]
        },
        {
          "output_type": "error",
          "ename": "Abort",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAbort\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-adeac6f00451>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mopendatasets\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mdownload_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'https://www.kaggle.com/datasets/jainilcoder/online-payment-fraud-detection'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownload_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/opendatasets/__init__.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(dataset_id_or_url, data_dir, force, dry_run, **kwargs)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Check for a Kaggle dataset URL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_kaggle_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_id_or_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdownload_kaggle_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_id_or_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdry_run\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdry_run\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# Check for Google Drive URL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/opendatasets/utils/kaggle_api.py\u001b[0m in \u001b[0;36mdownload_kaggle_dataset\u001b[0;34m(dataset_url, data_dir, force, dry_run)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mread_kaggle_creds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'KAGGLE_USERNAME'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclick\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Your Kaggle username\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'KAGGLE_KEY'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_kaggle_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/click/termui.py\u001b[0m in \u001b[0;36mprompt\u001b[0;34m(text, default, hide_input, confirmation_prompt, type, value_proc, prompt_suffix, show_default, err, show_choices)\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprompt_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/click/termui.py\u001b[0m in \u001b[0;36mprompt_func\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhide_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m                 \u001b[0mecho\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAbort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalue_proc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAbort\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Criar a coluna 'day' calculando os dias a partir de 'step' (considerando 24 horas por dia)\n",
        "df['day'] = (df['step'] // 24) + 1\n",
        "\n",
        "# Criar a coluna 'hour', que calcula as horas restantes no dia a partir de 'step'\n",
        "df['hour'] = (df['day'] * 24) - df['step']\n",
        "\n",
        "# Criar a coluna 'typeDest', pegando o primeiro caractere de 'nameDest'\n",
        "df['typeDest'] = df['nameDest'].str[0]\n",
        "\n",
        "# Criar a coluna 'emptyAccount', verificando se a conta foi esvaziada\n",
        "df['emptyAccount'] = np.where((df['oldbalanceOrg'] > 0) & (df['newbalanceOrig'] == 0), True, False)\n",
        "\n",
        "# Exibir as primeiras linhas do DataFrame para verificar o resultado\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qt0JweFyodL1",
        "outputId": "3a162e54-4048-48f0-b3e6-5b43f0449553"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   step      type    amount     nameOrig  oldbalanceOrg  newbalanceOrig  \\\n",
            "0     1   PAYMENT   9839.64  C1231006815       170136.0       160296.36   \n",
            "1     1   PAYMENT   1864.28  C1666544295        21249.0        19384.72   \n",
            "2     1  TRANSFER    181.00  C1305486145          181.0            0.00   \n",
            "3     1  CASH_OUT    181.00   C840083671          181.0            0.00   \n",
            "4     1   PAYMENT  11668.14  C2048537720        41554.0        29885.86   \n",
            "\n",
            "      nameDest  oldbalanceDest  newbalanceDest  isFraud  isFlaggedFraud  day  \\\n",
            "0  M1979787155             0.0             0.0        0               0    1   \n",
            "1  M2044282225             0.0             0.0        0               0    1   \n",
            "2   C553264065             0.0             0.0        1               0    1   \n",
            "3    C38997010         21182.0             0.0        1               0    1   \n",
            "4  M1230701703             0.0             0.0        0               0    1   \n",
            "\n",
            "   hour typeDest  emptyAccount  \n",
            "0    23        M         False  \n",
            "1    23        M         False  \n",
            "2    23        C          True  \n",
            "3    23        C          True  \n",
            "4    23        M         False  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGVh-hlYuDgf",
        "outputId": "c5fe2bc2-f0f2-414a-e8a8-b8c68c522bfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step              0\n",
            "type              0\n",
            "amount            0\n",
            "nameOrig          0\n",
            "oldbalanceOrg     0\n",
            "newbalanceOrig    0\n",
            "nameDest          0\n",
            "oldbalanceDest    0\n",
            "newbalanceDest    0\n",
            "isFraud           0\n",
            "isFlaggedFraud    0\n",
            "day               0\n",
            "hour              0\n",
            "typeDest          0\n",
            "emptyAccount      0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import IsolationForest\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "#Remover as colunas não necessárias\n",
        "df = df.drop(['nameOrig', 'nameDest'], axis=1)\n",
        "\n",
        "#One-Hot Encode de variáveis categóricas\n",
        "df = pd.get_dummies(df, columns=['type', 'typeDest', 'emptyAccount'], drop_first=False)\n",
        "\n",
        "#Objetivo é a predição da coluna IsFraud\n",
        "X = df.drop(['isFraud'], axis=1)\n",
        "y = df['isFraud']\n",
        "\n",
        "#Normalização dos dados\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "#Treinar modelo de Random Forest para seleção de features\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "#Treinar o modelo\n",
        "rf_model = RandomForestClassifier(n_estimators=50, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "#Obter as importâncias das características\n",
        "importances = rf_model.feature_importances_\n",
        "feature_importances_df = pd.DataFrame({'Feature': X.columns, 'Importance': importances})\n",
        "feature_importances_df = feature_importances_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "#Features mais importantes\n",
        "print(feature_importances)\n",
        "\n",
        "#\n",
        "top_features = feature_importances_df.head(10)['Feature'].tolist()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "1F8C7g5LBLop",
        "outputId": "5d50421c-1f4a-4e96-8db3-09d1802b0d17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-5d01d2255958>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#One-Hot Encode de variáveis categóricas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'type'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'typeDest'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'emptyAccount'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#Objetivo é a predição da coluna IsFraud\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/reshape/encoding.py\u001b[0m in \u001b[0;36mget_dummies\u001b[0;34m(data, prefix, prefix_sep, dummy_na, columns, sparse, drop_first, dtype)\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0;31m# Encoding only cols specified in columns. Get all cols not in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0;31m# columns to prepend to result.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m             \u001b[0mwith_dummies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0;31m# Encoding only object and category dtype columns. Get remaining\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5579\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[0;36m1.0\u001b[0m     \u001b[0;36m0.8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5580\u001b[0m         \"\"\"\n\u001b[0;32m-> 5581\u001b[0;31m         return super().drop(\n\u001b[0m\u001b[1;32m   5582\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5583\u001b[0m             \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4786\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4787\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4788\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4790\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4868\u001b[0m         \u001b[0mbm_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0maxis_num\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4869\u001b[0;31m         new_mgr = self._mgr.reindex_indexer(\n\u001b[0m\u001b[1;32m   4870\u001b[0m             \u001b[0mnew_axis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4871\u001b[0m             \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mreindex_indexer\u001b[0;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, only_slice, use_na_proxy)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m             new_blocks = self._slice_take_blocks_ax0(\n\u001b[0m\u001b[1;32m    681\u001b[0m                 \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m                 \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_slice_take_blocks_ax0\u001b[0;34m(self, slice_or_indexer, fill_value, only_slice, use_na_proxy, ref_inplace_op)\u001b[0m\n\u001b[1;32m    841\u001b[0m                             \u001b[0mblocks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 843\u001b[0;31m                         \u001b[0mnb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake_nd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtaker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_mgr_locs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    844\u001b[0m                         \u001b[0mblocks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mtake_nd\u001b[0;34m(self, indexer, axis, new_mgr_locs, fill_value)\u001b[0m\n\u001b[1;32m   1305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m         \u001b[0;31m# Note: algos.take_nd has upcast logic similar to coerce_to_target_dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1307\u001b[0;31m         new_values = algos.take_nd(\n\u001b[0m\u001b[1;32m   1308\u001b[0m             \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_fill\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_fill\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/array_algos/take.py\u001b[0m in \u001b[0;36mtake_nd\u001b[0;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_take_nd_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_fill\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/array_algos/take.py\u001b[0m in \u001b[0;36m_take_nd_ndarray\u001b[0;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     )\n\u001b[0;32m--> 162\u001b[0;31m     \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mflip_order\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Código acima não consegue rodar por alto consumo de RAM, sendo assim, foi escolhido reduzir numero de estimators, porém, também não solucionou o caso de consumo de RAM, por isso foi optado utilizar o max deth e diminuir a profundidade das árvores"
      ],
      "metadata": {
        "id": "lwOu5qqCGUCF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import IsolationForest\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "#Remover as colunas não necessárias\n",
        "df = df.drop(['nameOrig', 'nameDest'], axis=1)\n",
        "\n",
        "#One-Hot Encode de variáveis categóricas\n",
        "df = pd.get_dummies(df, columns=['type', 'typeDest', 'emptyAccount'], drop_first=False)\n",
        "\n",
        "#Objetivo é a predição da coluna IsFraud\n",
        "X = df.drop(['isFraud'], axis=1)\n",
        "y = df['isFraud']\n",
        "\n",
        "#Normalização dos dados\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "#Treinar modelo de Random Forest para seleção de features\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "#Treinar o modelo\n",
        "rf_model = RandomForestClassifier(n_estimators=50, max_depth=10, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "y_pred_rf = rf_model.predict(X_test)\n",
        "\n",
        "#Obter as importâncias das características\n",
        "importances = rf_model.feature_importances_\n",
        "feature_importances_df = pd.DataFrame({'Feature': X.columns, 'Importance': importances})\n",
        "feature_importances_df = feature_importances_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "#Features mais importantes\n",
        "print(feature_importances_df)\n",
        "\n",
        "# Top 10 features\n",
        "top_features = feature_importances_df.head(5)['Feature'].tolist()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDyuCPT9Gxp9",
        "outputId": "6a8dca86-6a20-45b2-e1b0-f32aa1d2db82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               Feature  Importance\n",
            "2        oldbalanceOrg    0.349478\n",
            "5       newbalanceDest    0.231926\n",
            "1               amount    0.077637\n",
            "0                 step    0.052385\n",
            "13       type_TRANSFER    0.048638\n",
            "4       oldbalanceDest    0.047276\n",
            "7                  day    0.045307\n",
            "8                 hour    0.044962\n",
            "10       type_CASH_OUT    0.039954\n",
            "16  emptyAccount_False    0.020647\n",
            "17   emptyAccount_True    0.014646\n",
            "14          typeDest_C    0.008877\n",
            "3       newbalanceOrig    0.006831\n",
            "12        type_PAYMENT    0.005971\n",
            "15          typeDest_M    0.003027\n",
            "6       isFlaggedFraud    0.001373\n",
            "9         type_CASH_IN    0.000874\n",
            "11          type_DEBIT    0.000193\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.ensemble import IsolationForest\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "conf_matrix = confusion_matrix(y_test, y_pred_rf)\n",
        "print(\"Matriz de Confusão:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "#Acuracidade\n",
        "print(f\"Acurácia Random Forest:  {accuracy_score(y_test, y_pred_rf)}\")\n",
        "print(classification_report(y_test, y_pred_rf))\n",
        "\n",
        "\n",
        "y_train_pred = rf_model.predict(X_train)\n",
        "y_test_pred = rf_model.predict(X_test)\n",
        "\n",
        "#Acuracia conjunto treino\n",
        "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "print(f\"Acurácia no conjunto de treinamento: {train_accuracy}\")\n",
        "print(classification_report(y_train, y_train_pred))\n",
        "\n",
        "#Acuracidade conjunto teste\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "print(f\"Acurácia no conjunto de teste: {test_accuracy}\")\n",
        "print(classification_report(y_test, y_test_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKqVc3m0Tj64",
        "outputId": "97f1414d-8fef-401d-890d-809bd7805838"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matriz de Confusão:\n",
            "[[1270899       5]\n",
            " [    389    1231]]\n",
            "Acurácia Random Forest:  0.9996903791205509\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00   1270904\n",
            "           1       1.00      0.76      0.86      1620\n",
            "\n",
            "    accuracy                           1.00   1272524\n",
            "   macro avg       1.00      0.88      0.93   1272524\n",
            "weighted avg       1.00      1.00      1.00   1272524\n",
            "\n",
            "Acurácia no conjunto de treinamento: 0.999683306562391\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00   5083503\n",
            "           1       1.00      0.76      0.86      6593\n",
            "\n",
            "    accuracy                           1.00   5090096\n",
            "   macro avg       1.00      0.88      0.93   5090096\n",
            "weighted avg       1.00      1.00      1.00   5090096\n",
            "\n",
            "Acurácia no conjunto de teste: 0.9996903791205509\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00   1270904\n",
            "           1       1.00      0.76      0.86      1620\n",
            "\n",
            "    accuracy                           1.00   1272524\n",
            "   macro avg       1.00      0.88      0.93   1272524\n",
            "weighted avg       1.00      1.00      1.00   1272524\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_features = ['oldbalanceOrg', 'newbalanceDest', 'amount', 'step', 'type_TRANSFER', 'oldbalanceDest', 'day', 'hour']\n",
        "top_indices = [list(df.columns).index(feature) for feature in top_features]\n",
        "\n",
        "# Treinar o modelo com as 10 melhores características\n",
        "X_train_top_features = X_train[:, top_indices]\n",
        "X_test_top_features = X_test[:, top_indices]\n",
        "\n",
        "rf_model_top_features = RandomForestClassifier(n_estimators=50, max_depth=10, random_state=42)\n",
        "rf_model_top_features.fit(X_train_top_features, y_train)\n",
        "\n",
        "y_pred_rf_top_features = rf_model_top_features.predict(X_test_top_features)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "conf_matrix = confusion_matrix(y_test, y_pred_rf_top_features)\n",
        "print(\"Matriz de Confusão:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "accuracy_top = accuracy_score(y_test, y_pred_rf_top_features)\n",
        "print(f\"Acurácia Random Forest com as 10 melhores características: {accuracy_top}\")\n",
        "print(classification_report(y_test, y_pred_rf_top_features))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVPhfywappCg",
        "outputId": "2cf40565-76b2-4f20-b45e-498d3e81b6c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matriz de Confusão:\n",
            "[[1270902       2]\n",
            " [    813     807]]\n",
            "Acurácia Random Forest com as 10 melhores características: 0.9993595405666219\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00   1270904\n",
            "           1       1.00      0.50      0.66      1620\n",
            "\n",
            "    accuracy                           1.00   1272524\n",
            "   macro avg       1.00      0.75      0.83   1272524\n",
            "weighted avg       1.00      1.00      1.00   1272524\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import IsolationForest\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "#\n",
        "X = df.drop(['isFraud', 'isFlaggedFraud'], axis=1)\n",
        "y = df['isFraud']\n",
        "\n",
        "#Dividir conjunto de testes\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Seleciona as melhores características\n",
        "k = 5\n",
        "selector = SelectKBest(score_func=mutual_info_classif, k=k)\n",
        "X_new = selector.fit_transform(X_train, y_train)\n",
        "X_test_selected = selector.transform(X_test)\n",
        "\n",
        "# Obter as colunas selecionadas\n",
        "selected_features = np.array(X.columns)[selector.get_support()]\n",
        "\n",
        "print(f\"Scores das features: {selected_features}\")\n",
        "print(selected_features)\n",
        "\n",
        "# Treinar o modelo com as 10 melhores características\n",
        "rf_model = RandomForestClassifier(n_estimators=50, max_depth=10, random_state=42)\n",
        "rf_model.fit(X_new, y_train)\n",
        "\n",
        "y_pred = rf_model.predict(X_test_selected)\n",
        "\n",
        "# Avaliar o desempenho do modelo\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Acurácia do modelo: {accuracy}\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "print(\"Matriz de Confusão:\")\n",
        "print(conf_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPEt48QMA684",
        "outputId": "41e1944a-e71d-4298-9d6d-4ea77e1de909"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scores das features: ['day' 'hour' 'type_CASH_IN' 'type_TRANSFER' 'emptyAccount_True']\n",
            "['day' 'hour' 'type_CASH_IN' 'type_TRANSFER' 'emptyAccount_True']\n",
            "Acurácia do modelo: 0.9991340045452973\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00   1270904\n",
            "           1       0.92      0.35      0.51      1620\n",
            "\n",
            "    accuracy                           1.00   1272524\n",
            "   macro avg       0.96      0.67      0.75   1272524\n",
            "weighted avg       1.00      1.00      1.00   1272524\n",
            "\n",
            "Matriz de Confusão:\n",
            "[[1270855      49]\n",
            " [   1053     567]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **UTILIZANDO MÉTODOS PREDITIVOS**"
      ],
      "metadata": {
        "id": "ECcVauO8BMTl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhC1kqgd9EYw",
        "outputId": "4ba429e1-22ff-41fa-8a8d-ad8cef5ddc6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping, found downloaded files in \"./online-payment-fraud-detection\" (use force=True to force download)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd\n",
        "!pip install opendatasets --upgrade --quiet\n",
        "\n",
        "import opendatasets as od\n",
        "download_url = 'https://www.kaggle.com/datasets/jainilcoder/online-payment-fraud-detection'\n",
        "od.download(download_url)\n",
        "\n",
        "\n",
        "df= pd.read_csv('./online-payment-fraud-detection/onlinefraud.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Criar a coluna 'day' calculando os dias a partir de 'step' (considerando 24 horas por dia)\n",
        "df['day'] = (df['step'] // 24) + 1\n",
        "\n",
        "# Criar a coluna 'hour', que calcula as horas restantes no dia a partir de 'step'\n",
        "df['hour'] = (df['day'] * 24) - df['step']\n",
        "\n",
        "# Criar a coluna 'typeDest', pegando o primeiro caractere de 'nameDest'\n",
        "df['typeDest'] = df['nameDest'].str[0]\n",
        "\n",
        "# Criar a coluna 'emptyAccount', verificando se a conta foi esvaziada\n",
        "df['emptyAccount'] = np.where((df['oldbalanceOrg'] > 0) & (df['newbalanceOrig'] == 0), True, False)\n",
        "\n",
        "# Exibir as primeiras linhas do DataFrame para verificar o resultado\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUsnTj1xEtbr",
        "outputId": "14545061-a8ca-473b-db7b-e09bb050fbfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   step      type    amount     nameOrig  oldbalanceOrg  newbalanceOrig  \\\n",
            "0     1   PAYMENT   9839.64  C1231006815       170136.0       160296.36   \n",
            "1     1   PAYMENT   1864.28  C1666544295        21249.0        19384.72   \n",
            "2     1  TRANSFER    181.00  C1305486145          181.0            0.00   \n",
            "3     1  CASH_OUT    181.00   C840083671          181.0            0.00   \n",
            "4     1   PAYMENT  11668.14  C2048537720        41554.0        29885.86   \n",
            "\n",
            "      nameDest  oldbalanceDest  newbalanceDest  isFraud  isFlaggedFraud  day  \\\n",
            "0  M1979787155             0.0             0.0        0               0    1   \n",
            "1  M2044282225             0.0             0.0        0               0    1   \n",
            "2   C553264065             0.0             0.0        1               0    1   \n",
            "3    C38997010         21182.0             0.0        1               0    1   \n",
            "4  M1230701703             0.0             0.0        0               0    1   \n",
            "\n",
            "   hour typeDest  emptyAccount  \n",
            "0    23        M         False  \n",
            "1    23        M         False  \n",
            "2    23        C          True  \n",
            "3    23        C          True  \n",
            "4    23        M         False  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "horarios_com_mais_fraudes = df[df['isFraud'] == 1].groupby('hour').size().sort_values(ascending=False)\n",
        "\n",
        "print(horarios_com_mais_fraudes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8ZG6wX4rzsY",
        "outputId": "bd5fe461-bf4a-4dc2-ad30-b36808781b2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hour\n",
            "14    375\n",
            "22    372\n",
            "16    368\n",
            "19    366\n",
            "23    358\n",
            "18    358\n",
            "10    353\n",
            "7     353\n",
            "2     351\n",
            "3     347\n",
            "11    346\n",
            "8     345\n",
            "6     343\n",
            "5     342\n",
            "9     341\n",
            "15    341\n",
            "4     340\n",
            "12    339\n",
            "17    328\n",
            "21    326\n",
            "13    324\n",
            "1     323\n",
            "24    300\n",
            "20    274\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fraudes = df[df['isFraud'] == 1]\n",
        "\n",
        "#agrupar por hour e contar o volume de fraudes\n",
        "horarios_com_mais_fraudes = fraudes.groupby('hour').size().reset_index(name='num_fraudes')\n",
        "\n",
        "#ordenar em ordem decrescente\n",
        "horarios_com_maiores_valores = fraudes.groupby('hour')['amount'].sum().reset_index(name='total_amount')\n",
        "\n",
        "#Criterio de corte horarios com mais fraudes e maiores valores\n",
        "top_horarios_fraude_volume = horarios_com_mais_fraudes.nlargest(12, 'num_fraudes')\n",
        "top_horarios_fraude_valores = horarios_com_maiores_valores.nlargest(13, 'total_amount')\n",
        "\n",
        "#Unir os dois dataframes\n",
        "top_horarios = pd.merge(top_horarios_fraude_volume, top_horarios_fraude_valores, on='hour')\n",
        "\n",
        "print(top_horarios)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9W71a-FAumqK",
        "outputId": "d80ba28a-2ad4-4933-90f4-e17b24a587e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   hour  num_fraudes  total_amount\n",
            "0    14          375  6.883396e+08\n",
            "1    22          372  7.001793e+08\n",
            "2    16          368  6.213458e+08\n",
            "3    19          366  5.027237e+08\n",
            "4     7          353  5.745757e+08\n",
            "5    10          353  6.494727e+08\n",
            "6     2          351  6.257006e+08\n",
            "7     3          347  6.791250e+08\n",
            "8    11          346  4.753662e+08\n",
            "9     8          345  5.177531e+08\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_filtrado = df[df['hour'].isin(df['hour'])]\n",
        "df_filtrado = df_filtrado[(df_filtrado['type'] == 'CASH_OUT') | (df_filtrado['type'] == 'TRANSFER')]\n",
        "print(df_filtrado.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQSqKCsiyU-7",
        "outputId": "97596053-5c91-4a88-91cd-19ab7c85699e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    step      type     amount     nameOrig  oldbalanceOrg  newbalanceOrig  \\\n",
            "2      1  TRANSFER     181.00  C1305486145          181.0             0.0   \n",
            "3      1  CASH_OUT     181.00   C840083671          181.0             0.0   \n",
            "15     1  CASH_OUT  229133.94   C905080434        15325.0             0.0   \n",
            "19     1  TRANSFER  215310.30  C1670993182          705.0             0.0   \n",
            "24     1  TRANSFER  311685.89  C1984094095        10835.0             0.0   \n",
            "\n",
            "       nameDest  oldbalanceDest  newbalanceDest  isFraud  isFlaggedFraud  day  \\\n",
            "2    C553264065             0.0            0.00        1               0    1   \n",
            "3     C38997010         21182.0            0.00        1               0    1   \n",
            "15   C476402209          5083.0        51513.44        0               0    1   \n",
            "19  C1100439041         22425.0            0.00        0               0    1   \n",
            "24   C932583850          6267.0      2719172.89        0               0    1   \n",
            "\n",
            "    hour typeDest  emptyAccount  \n",
            "2     23        C          True  \n",
            "3     23        C          True  \n",
            "15    23        C          True  \n",
            "19    23        C          True  \n",
            "24    23        C          True  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Com seleção de features**"
      ],
      "metadata": {
        "id": "KcuDMp0U6rd-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Remover as colunas não necessárias\n",
        "df_filtrado = df_filtrado.drop(['nameOrig', 'nameDest', \"isFlaggedFraud\"], axis=1)\n",
        "\n",
        "#One-Hot Encode de variáveis categóricas\n",
        "df_filtrado = pd.get_dummies(df_filtrado, columns=['type', 'typeDest', 'emptyAccount'], drop_first=False)\n",
        "\n",
        "#Objetivo é a predição da coluna IsFraud\n",
        "X = df_filtrado.drop(['isFraud'], axis=1)\n",
        "y = df_filtrado['isFraud']\n",
        "\n",
        "#Normalização dos dados\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "#Treinar modelo de Random Forest para seleção de features\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Seleciona as melhores características\n",
        "k = 10\n",
        "selector = SelectKBest(score_func=f_classif, k=k)\n",
        "X_train_selected = selector.fit_transform(X_train, y_train)\n",
        "X_test_selected = selector.transform(X_test)\n",
        "\n",
        "# Obter as colunas selecionadas\n",
        "selected_features = np.array(X.columns)[selector.get_support()]\n",
        "\n",
        "print(\"Melhores características selecionadas:\")\n",
        "print(selected_features)\n",
        "\n",
        "# Árvore de Decisão\n",
        "clf_tree = DecisionTreeClassifier(max_depth=20, random_state=42)\n",
        "clf_tree.fit(X_train_selected, y_train)\n",
        "y_pred_tree = clf_tree.predict(X_test_selected)\n",
        "print(\"Árvore de Decisão\")\n",
        "print(\"Acurácia:\", accuracy_score(y_test, y_pred_tree))\n",
        "print(\"Relatório de Classificação:\\n\", classification_report(y_test, y_pred_tree))\n",
        "\n",
        "# Gerar a matriz de confusão\n",
        "cm = confusion_matrix(y_test, y_pred_tree)\n",
        "print(\"Matriz de Confusão árvore de decisão:\")\n",
        "print(cm)\n",
        "\n",
        "#Conjunto treino arvore de decisão\n",
        "y_pred_tree_train = clf_tree.predict(X_train_selected)\n",
        "\n",
        "#Acuracidade conjunto traino arvore\n",
        "test_accuracy = accuracy_score(y_train, y_pred_tree_train)\n",
        "print(f\"Acurácia no conjunto de teste arvore de decisão: {test_accuracy}\")\n",
        "print(classification_report(y_train, y_pred_tree_train))\n",
        "\n",
        "# Gerar a matriz de confusão treino arvore de decisão\n",
        "cm = confusion_matrix(y_train, y_pred_tree_train)\n",
        "print(\"Matriz de Confusão treino árvore de decisão:\")\n",
        "print(cm)\n",
        "\n",
        "# Regressão Logística\n",
        "clf_logreg = LogisticRegression(max_iter=1000, random_state=42)\n",
        "clf_logreg.fit(X_train_selected, y_train)\n",
        "y_pred_logreg = clf_logreg.predict(X_test_selected)\n",
        "print(\"Regressão Logística\")\n",
        "print(\"Acurácia:\", accuracy_score(y_test, y_pred_logreg))\n",
        "print(\"Relatório de Classificação:\\n\", classification_report(y_test, y_pred_logreg))\n",
        "\n",
        "# Gerar a matriz de confusão\n",
        "cm = confusion_matrix(y_test, y_pred_logreg)\n",
        "print(\"Matriz de Confusão regressão logística:\")\n",
        "print(cm)\n",
        "\n",
        "#Conjunto treino regressão logística\n",
        "y_pred_logreg_train = clf_logreg.predict(X_train_selected)\n",
        "\n",
        "#Acuracidade conjunto traino regressão logistica\n",
        "test_accuracy = accuracy_score(y_train, y_pred_logreg_train)\n",
        "print(f\"Acurácia no conjunto de teste regressão logistica: {test_accuracy}\")\n",
        "print(classification_report(y_train, y_pred_logreg_train))\n",
        "\n",
        "# Gerar a matriz de confusão treino regressão logistica\n",
        "cm = confusion_matrix(y_train, y_pred_logreg_train)\n",
        "print(\"Matriz de Confusão treino regressão logistica:\")\n",
        "print(cm)\n",
        "\n",
        "# XGBoost\n",
        "clf_xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
        "clf_xgb.fit(X_train_selected, y_train)\n",
        "y_pred_xgb = clf_xgb.predict(X_test_selected)\n",
        "print(\"XGBoost\")\n",
        "print(\"Acurácia:\", accuracy_score(y_test, y_pred_xgb))\n",
        "print(\"Relatório de Classificação:\\n\", classification_report(y_test, y_pred_xgb))\n",
        "\n",
        "# Gerar a matriz de confusão\n",
        "cm = confusion_matrix(y_test, y_pred_xgb)\n",
        "print(\"Matriz de Confusão XGBoost:\")\n",
        "print(cm)\n",
        "\n",
        "#Conjunto treino XGBOOST\n",
        "y_pred_xgb_train = clf_xgb.predict(X_train_selected)\n",
        "\n",
        "#Acuracidade conjunto traino XGBOOST\n",
        "test_accuracy = accuracy_score(y_train, y_pred_xgb_train)\n",
        "print(f\"Acurácia no conjunto de teste XGBOOST: {test_accuracy}\")\n",
        "print(classification_report(y_train, y_pred_xgb_train))\n",
        "\n",
        "# Gerar a matriz de confusão treino XGBOOST\n",
        "cm = confusion_matrix(y_train, y_pred_xgb_train)\n",
        "print(\"Matriz de Confusão treino XGBOOST:\")\n",
        "print(cm)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSXn4dpIE1QO",
        "outputId": "fcadcc5b-384a-4218-bd23-60fd5faee699"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [10] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Melhores características selecionadas:\n",
            "['step' 'amount' 'oldbalanceOrg' 'newbalanceOrig' 'day' 'hour'\n",
            " 'type_CASH_OUT' 'type_TRANSFER' 'emptyAccount_False' 'emptyAccount_True']\n",
            "Árvore de Decisão\n",
            "Acurácia: 0.9991860410552951\n",
            "Relatório de Classificação:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00    552436\n",
            "           1       0.89      0.82      0.86      1646\n",
            "\n",
            "    accuracy                           1.00    554082\n",
            "   macro avg       0.95      0.91      0.93    554082\n",
            "weighted avg       1.00      1.00      1.00    554082\n",
            "\n",
            "Matriz de Confusão árvore de decisão:\n",
            "[[552276    160]\n",
            " [   291   1355]]\n",
            "Acurácia no conjunto de teste arvore de decisão: 0.9996679190390226\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00   2209760\n",
            "           1       0.99      0.90      0.94      6567\n",
            "\n",
            "    accuracy                           1.00   2216327\n",
            "   macro avg       0.99      0.95      0.97   2216327\n",
            "weighted avg       1.00      1.00      1.00   2216327\n",
            "\n",
            "Matriz de Confusão treino árvore de decisão:\n",
            "[[2209676      84]\n",
            " [    652    5915]]\n",
            "Regressão Logística\n",
            "Acurácia: 0.9985453416642303\n",
            "Relatório de Classificação:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00    552436\n",
            "           1       0.93      0.55      0.69      1646\n",
            "\n",
            "    accuracy                           1.00    554082\n",
            "   macro avg       0.96      0.78      0.85    554082\n",
            "weighted avg       1.00      1.00      1.00    554082\n",
            "\n",
            "Matriz de Confusão regressão logística:\n",
            "[[552366     70]\n",
            " [   736    910]]\n",
            "Acurácia no conjunto de teste regressão logistica: 0.9984880389942459\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00   2209760\n",
            "           1       0.92      0.54      0.68      6567\n",
            "\n",
            "    accuracy                           1.00   2216327\n",
            "   macro avg       0.96      0.77      0.84   2216327\n",
            "weighted avg       1.00      1.00      1.00   2216327\n",
            "\n",
            "Matriz de Confusão treino regressão logistica:\n",
            "[[2209441     319]\n",
            " [   3032    3535]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [00:54:33] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost\n",
            "Acurácia: 0.999440516024704\n",
            "Relatório de Classificação:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00    552436\n",
            "           1       0.94      0.87      0.90      1646\n",
            "\n",
            "    accuracy                           1.00    554082\n",
            "   macro avg       0.97      0.94      0.95    554082\n",
            "weighted avg       1.00      1.00      1.00    554082\n",
            "\n",
            "Matriz de Confusão XGBoost:\n",
            "[[552337     99]\n",
            " [   211   1435]]\n",
            "Acurácia no conjunto de teste XGBOOST: 0.9996318232823947\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00   2209760\n",
            "           1       0.97      0.90      0.94      6567\n",
            "\n",
            "    accuracy                           1.00   2216327\n",
            "   macro avg       0.99      0.95      0.97   2216327\n",
            "weighted avg       1.00      1.00      1.00   2216327\n",
            "\n",
            "Matriz de Confusão treino XGBOOST:\n",
            "[[2209593     167]\n",
            " [    649    5918]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sem seleção de features**"
      ],
      "metadata": {
        "id": "wqm_jbm56yKn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Remover as colunas não necessárias\n",
        "df_filtrado = df_filtrado.drop(['nameOrig', 'nameDest', 'isFlaggedFraud'], axis=1)\n",
        "\n",
        "#One-Hot Encode de variáveis categóricas\n",
        "df_filtrado = pd.get_dummies(df_filtrado, columns=['type', 'typeDest', 'emptyAccount'], drop_first=False)\n",
        "\n",
        "#Objetivo é a predição da coluna IsFraud\n",
        "X = df_filtrado.drop(['isFraud'], axis=1)\n",
        "y = df_filtrado['isFraud']\n",
        "\n",
        "#Normalização dos dados\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "#Treinar modelo de Random Forest para seleção de features\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Árvore de Decisão\n",
        "clf_tree = DecisionTreeClassifier(random_state=42)\n",
        "clf_tree.fit(X_train, y_train)\n",
        "y_pred_tree = clf_tree.predict(X_test)\n",
        "print(\"Árvore de Decisão\")\n",
        "print(\"Acurácia:\", accuracy_score(y_test, y_pred_tree))\n",
        "print(\"Relatório de Classificação:\\n\", classification_report(y_test, y_pred_tree))\n",
        "\n",
        "# Gerar a matriz de confusão\n",
        "cm = confusion_matrix(y_test, y_pred_tree)\n",
        "print(\"Matriz de Confusão árvore de decisão:\")\n",
        "print(cm)\n",
        "\n",
        "#Conjunto treino arvore de decisão\n",
        "y_pred_tree_train = clf_tree.predict(X_train)\n",
        "\n",
        "#Acuracidade conjunto traino arvore\n",
        "test_accuracy = accuracy_score(y_train, y_pred_tree_train)\n",
        "print(f\"Acurácia no conjunto de teste arvore de decisão: {test_accuracy}\")\n",
        "print(classification_report(y_train, y_pred_tree_train))\n",
        "\n",
        "# Gerar a matriz de confusão treino arvore de decisão\n",
        "cm = confusion_matrix(y_train, y_pred_tree_train)\n",
        "print(\"Matriz de Confusão treino árvore de decisão:\")\n",
        "print(cm)\n",
        "\n",
        "\n",
        "# Regressão Logística\n",
        "clf_logreg = LogisticRegression(max_iter=1000, random_state=42)\n",
        "clf_logreg.fit(X_train, y_train)\n",
        "y_pred_logreg = clf_logreg.predict(X_test)\n",
        "print(\"Regressão Logística\")\n",
        "print(\"Acurácia:\", accuracy_score(y_test, y_pred_logreg))\n",
        "print(\"Relatório de Classificação:\\n\", classification_report(y_test, y_pred_logreg))\n",
        "\n",
        "# Gerar a matriz de confusão\n",
        "cm = confusion_matrix(y_test, y_pred_logreg)\n",
        "print(\"Matriz de Confusão regressão logística:\")\n",
        "print(cm)\n",
        "\n",
        "#Conjunto treino regressão logística\n",
        "y_pred_logreg_train = clf_logreg.predict(X_train)\n",
        "\n",
        "#Acuracidade conjunto traino regressão logistica\n",
        "test_accuracy = accuracy_score(y_train, y_pred_logreg_train)\n",
        "print(f\"Acurácia no conjunto de teste regressão logistica: {test_accuracy}\")\n",
        "print(classification_report(y_train, y_pred_logreg_train))\n",
        "\n",
        "# Gerar a matriz de confusão treino regressão logistica\n",
        "cm = confusion_matrix(y_train, y_pred_logreg_train)\n",
        "print(\"Matriz de Confusão treino regressão logistica:\")\n",
        "print(cm)\n",
        "\n",
        "# XGBoost\n",
        "clf_xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
        "clf_xgb.fit(X_train, y_train)\n",
        "y_pred_xgb = clf_xgb.predict(X_test)\n",
        "print(\"XGBoost\")\n",
        "print(\"Acurácia:\", accuracy_score(y_test, y_pred_xgb))\n",
        "print(\"Relatório de Classificação:\\n\", classification_report(y_test, y_pred_xgb))\n",
        "\n",
        "# Gerar a matriz de confusão\n",
        "cm = confusion_matrix(y_test, y_pred_xgb)\n",
        "print(\"Matriz de Confusão XGBoost:\")\n",
        "print(cm)\n",
        "\n",
        "#Conjunto treino XGBOOST\n",
        "y_pred_xgb_train = clf_xgb.predict(X_train)\n",
        "\n",
        "#Acuracidade conjunto traino XGBOOST\n",
        "test_accuracy = accuracy_score(y_train, y_pred_xgb_train)\n",
        "print(f\"Acurácia no conjunto de teste XGBOOST: {test_accuracy}\")\n",
        "print(classification_report(y_train, y_pred_xgb_train))\n",
        "\n",
        "# Gerar a matriz de confusão treino XGBOOST\n",
        "cm = confusion_matrix(y_train, y_pred_xgb_train)\n",
        "print(\"Matriz de Confusão treino XGBOOST:\")\n",
        "print(cm)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ayxu97lg1sBN",
        "outputId": "b685e334-9811-4072-8a99-dc938442aea3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Árvore de Decisão\n",
            "Acurácia: 0.9992762804061492\n",
            "Relatório de Classificação:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00    552436\n",
            "           1       0.89      0.87      0.88      1646\n",
            "\n",
            "    accuracy                           1.00    554082\n",
            "   macro avg       0.94      0.93      0.94    554082\n",
            "weighted avg       1.00      1.00      1.00    554082\n",
            "\n",
            "Matriz de Confusão árvore de decisão:\n",
            "[[552256    180]\n",
            " [   221   1425]]\n",
            "Acurácia no conjunto de teste arvore de decisão: 1.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00   2209760\n",
            "           1       1.00      1.00      1.00      6567\n",
            "\n",
            "    accuracy                           1.00   2216327\n",
            "   macro avg       1.00      1.00      1.00   2216327\n",
            "weighted avg       1.00      1.00      1.00   2216327\n",
            "\n",
            "Matriz de Confusão treino árvore de decisão:\n",
            "[[2209760       0]\n",
            " [      0    6567]]\n",
            "Regressão Logística\n",
            "Acurácia: 0.9986030948487769\n",
            "Relatório de Classificação:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00    552436\n",
            "           1       0.94      0.57      0.71      1646\n",
            "\n",
            "    accuracy                           1.00    554082\n",
            "   macro avg       0.97      0.78      0.85    554082\n",
            "weighted avg       1.00      1.00      1.00    554082\n",
            "\n",
            "Matriz de Confusão regressão logística:\n",
            "[[552375     61]\n",
            " [   713    933]]\n",
            "Acurácia no conjunto de teste regressão logistica: 0.9985430850231035\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00   2209760\n",
            "           1       0.93      0.55      0.69      6567\n",
            "\n",
            "    accuracy                           1.00   2216327\n",
            "   macro avg       0.96      0.78      0.85   2216327\n",
            "weighted avg       1.00      1.00      1.00   2216327\n",
            "\n",
            "Matriz de Confusão treino regressão logistica:\n",
            "[[2209469     291]\n",
            " [   2938    3629]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [16:46:04] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost\n",
            "Acurácia: 0.9995867037730878\n",
            "Relatório de Classificação:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00    552436\n",
            "           1       0.97      0.89      0.93      1646\n",
            "\n",
            "    accuracy                           1.00    554082\n",
            "   macro avg       0.98      0.95      0.96    554082\n",
            "weighted avg       1.00      1.00      1.00    554082\n",
            "\n",
            "Matriz de Confusão XGBoost:\n",
            "[[552386     50]\n",
            " [   179   1467]]\n",
            "Acurácia no conjunto de teste XGBOOST: 0.9997545488549298\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00   2209760\n",
            "           1       0.99      0.92      0.96      6567\n",
            "\n",
            "    accuracy                           1.00   2216327\n",
            "   macro avg       1.00      0.96      0.98   2216327\n",
            "weighted avg       1.00      1.00      1.00   2216327\n",
            "\n",
            "Matriz de Confusão treino XGBOOST:\n",
            "[[2209720      40]\n",
            " [    504    6063]]\n"
          ]
        }
      ]
    }
  ]
}